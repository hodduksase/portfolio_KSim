# 🛠️ 기술 스택 상세 정리
## 데이터분석사 포트폴리오 기술 역량

---

## 📊 **데이터 처리 & 분석**

### **Pandas (v1.5.0+)**
- **활용 분야**: 데이터 조작, 전처리, 피벗 테이블
- **주요 기능**:
  - KBO 선수 데이터 로드 및 정제
  - 연도별, 포지션별 데이터 그룹핑
  - 결측치 처리 및 데이터 타입 변환
  - 특성 엔지니어링 (수상 지표 계산, 성과 지수 생성)

### **NumPy (v1.21.0+)**
- **활용 분야**: 수치 계산, 배열 처리, 통계 연산
- **주요 기능**:
  - 선수 성과 지표의 수치적 계산
  - 배열 기반 데이터 처리
  - 수학적 연산 및 통계 함수 활용

### **PyODBC**
- **활용 분야**: 데이터베이스 연결 및 쿼리
- **주요 기능**:
  - KBO historical_database.odb 파일 연결
  - SQL 쿼리를 통한 데이터 추출
  - 대용량 데이터 처리 및 최적화

---

## 🤖 **머신러닝 & 통계**

### **Scikit-learn (v1.1.0+)**
- **활용 분야**: 다양한 ML 알고리즘 구현 및 모델 훈련
- **주요 모델**:

#### **회귀 모델**
- **Random Forest Regressor**: 연봉 예측의 핵심 모델
- **Gradient Boosting Regressor**: 앙상블 기반 예측
- **Linear Regression**: 기본 선형 관계 모델링
- **Ridge Regression**: 정규화를 통한 과적합 방지
- **Lasso Regression**: 특성 선택을 통한 차원 축소
- **Support Vector Regression (SVR)**: 비선형 관계 모델링

#### **모델 평가 및 검증**
- **Cross-validation**: 모델 성능의 안정성 검증
- **GridSearchCV**: 하이퍼파라미터 최적화
- **Feature Selection**: SelectKBest를 통한 특성 선택

### **Joblib (v1.2.0+)**
- **활용 분야**: 모델 저장 및 로딩
- **주요 기능**:
  - 훈련된 모델의 영구 저장
  - 모델 재사용 및 배포 지원
  - 대용량 모델의 효율적 관리

### **SciPy (v1.7.0+)**
- **활용 분야**: 통계 검정 및 분석
- **주요 기능**:
  - 상관관계 분석 및 검정
  - 정규성 검정
  - 통계적 유의성 검증

### **StatsModels (v0.13.0+)**
- **활용 분야**: 회귀 분석 및 시계열 분석
- **주요 기능**:
  - 선형 회귀 모델의 상세 분석
  - 잔차 분석 및 모델 진단
  - 통계적 유의성 검증

---

## 📈 **시각화 & 대시보드**

### **Matplotlib (v3.5.0+)**
- **활용 분야**: 기본 차트 및 그래프 생성
- **주요 차트**:
  - 산점도: 연봉 vs 성과 지표 관계
  - 히스토그램: 수상 점수 분포
  - 박스플롯: 포지션별 성과 비교
  - 선 그래프: 연도별 트렌드

### **Seaborn (v0.11.0+)**
- **활용 분야**: 통계 시각화 및 고급 차트
- **주요 기능**:
  - 상관관계 히트맵
  - 분포 플롯
  - 회귀 플롯
  - 한글 폰트 지원

### **인터랙티브 시각화**
- **활용 분야**: 동적 데이터 시각화
- **주요 기능**:
  - 호버 정보 표시
  - 줌인/줌아웃 기능
  - 필터링 및 정렬

---

## 🔧 **데이터베이스 & 파일 처리**

### **ODB 파일 처리**
- **파일 형식**: Microsoft Access Database (.odb)
- **처리 방식**: PyODBC를 통한 연결 및 쿼리
- **데이터 크기**: 2020-2024년 KBO 선수 데이터

### **CSV 파일 처리**
- **입력**: ODB에서 추출한 원본 데이터
- **출력**: 연도별, 포지션별 분리된 CSV 파일
- **데이터 정제**: 한국 선수 필터링, 결측치 처리

---

## 📋 **개발 도구 & 환경**

### **Python 환경**
- **버전**: Python 3.8+
- **가상환경**: pip 기반 패키지 관리
- **의존성 관리**: requirements.txt

### **코드 품질**
- **코딩 스타일**: PEP 8 준수
- **문서화**: 상세한 주석 및 docstring
- **에러 처리**: try-catch를 통한 안정성 확보

---

## 🚀 **배포 & 실행**

### **실행 스크립트**
- **메인 파이프라인**: 전체 분석 과정 자동화
- **개별 모듈**: 특정 기능별 독립 실행
- **배치 처리**: 대용량 데이터 처리 지원

### **결과 저장**
- **모델 파일**: .pkl 형식으로 저장
- **차트 이미지**: PNG, JPG 형식으로 저장
- **분석 리포트**: 텍스트 및 마크다운 형식

---

## 📊 **성능 최적화**

### **메모리 관리**
- **청크 단위 처리**: 대용량 데이터의 효율적 처리
- **데이터 타입 최적화**: 메모리 사용량 최소화
- **가비지 컬렉션**: 메모리 누수 방지

### **처리 속도**
- **벡터화 연산**: NumPy 기반 고속 계산
- **병렬 처리**: 멀티코어 활용
- **알고리즘 최적화**: 효율적인 ML 알고리즘 선택

---

## 🔮 **향후 기술 확장 계획**

### **딥러닝 도입**
- **TensorFlow/PyTorch**: 신경망 기반 모델
- **LSTM**: 시계열 데이터 분석
- **Transformer**: 복잡한 패턴 인식

### **클라우드 활용**
- **AWS/GCP**: 대용량 데이터 처리
- **Docker**: 컨테이너 기반 배포
- **Kubernetes**: 확장 가능한 인프라

### **웹 개발**
- **Flask/Django**: 웹 API 개발
- **React/Vue**: 프론트엔드 대시보드
- **Streamlit**: 빠른 프로토타이핑

---

## 📈 **기술 역량 수준**

### **고급 수준 (Advanced)**
- **머신러닝**: 다양한 알고리즘의 깊이 있는 이해
- **데이터 처리**: 대용량 데이터의 효율적 처리
- **시각화**: 복잡한 데이터의 명확한 표현

### **중급 수준 (Intermediate)**
- **통계 분석**: 기본적인 통계 검정 및 해석
- **데이터베이스**: SQL 쿼리 및 데이터 추출
- **코딩**: Python 기반 체계적인 코드 작성

### **기초 수준 (Basic)**
- **웹 개발**: 기본적인 웹 인터페이스 구축
- **클라우드**: 클라우드 서비스 활용
- **DevOps**: CI/CD 파이프라인 구축

---

## 🎯 **기술 스택 활용 사례**

### **실제 프로젝트에서의 활용**
1. **데이터 수집**: PyODBC를 통한 KBO 데이터베이스 연결
2. **데이터 전처리**: Pandas를 통한 데이터 정제 및 특성 엔지니어링
3. **모델 개발**: Scikit-learn을 통한 다양한 ML 모델 구현
4. **성능 평가**: Cross-validation을 통한 모델 검증
5. **결과 시각화**: Matplotlib/Seaborn을 통한 인사이트 도출
6. **모델 배포**: Joblib을 통한 모델 저장 및 재사용

이러한 기술 스택을 통해 **실무에서 바로 활용 가능한 데이터 분석 시스템**을 구축했습니다.
